version: '3'
services:
# spark master
    sparkmaster:       
        image: holtri/spark-master
        ports:
            - "8080:8080"
        networks:
            - energydata_nw
            
# cassandra + spark-slave
    node1:       
        image: holtri/cassandra-sparkslave
        depends_on:
            - sparkmaster 
        volumes:
            - ./node-1-data:/var/lib/cassandra
        environment:
            - CASSANDRA_CLUSTER_NAME=mega
            - SPARKMASTER=sparkmaster
        expose:
            - 7000
            - 7001
            - 7199
            - 9042
            - 9160
        ulimits:
            memlock: -1
            nproc: 32768
            nofile: 100000
        networks:
            - energydata_nw
 
    node2:       
        image: holtri/cassandra-sparkslave
        depends_on:
            - sparkmaster
        volumes:
            - ./node-2-data:/var/lib/cassandra
        environment:
            - CASSANDRA_CLUSTER_NAME=mega
            - CASSANDRA_SEEDS=node1
        expose:
            - 7000
            - 7001
            - 7199
            - 9042
            - 9160
        ulimits:
            memlock: -1
            nproc: 32768
            nofile: 100000   
        networks:
            - energydata_nw
# kafka
    zookeeper:
        image: confluentinc/cp-zookeeper
        hostname: zookeeper
        ports:
          - "2181:2181"
        environment:
          ZOOKEEPER_CLIENT_PORT: 2181
          ZOOKEEPER_TICK_TIME: 2000
        networks:
            - energydata_nw
            
    broker:
        image: confluentinc/cp-kafka
        hostname: broker
        depends_on:
          - zookeeper
        ports:
          - "9092:9092"
        environment:
          KAFKA_BROKER_ID: 1
          KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
          KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker:9092'
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
          KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        networks:
            - energydata_nw
            
    schema_registry:
        image: confluentinc/cp-schema-registry
        hostname: schema_registry
        depends_on:
          - zookeeper
          - broker
        ports:
          - "8081:8081"
        environment:
          SCHEMA_REGISTRY_HOST_NAME: schema_registry
          SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'
        networks:
            - energydata_nw
            
    connect:
        image: confluentinc/cp-kafka-connect
        hostname: connect
        depends_on:
            - zookeeper
            - broker
            - schema_registry
        ports:
            - "8083:8083"
        environment:
            CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
            CONNECT_REST_ADVERTISED_HOST_NAME: connect
            CONNECT_REST_PORT: 8083
            CONNECT_GROUP_ID: compose-connect-group
            CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
            CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
            CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
            CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
            CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
            CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
            CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
            CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
            CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema_registry:8081'
            CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
            CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema_registry:8081'
            CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
            CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
            CONNECT_ZOOKEEPER_CONNECT: 'zookeeper:2181'
        networks:
            - energydata_nw

# Jupyter Notebook
    jupyter:
        image: jupyter/pyspark-notebook
        # for custom password append  --NotebookApp.password='sha1:74ba40f8a388:c913541b7ee99d15d5ed31d4226bf7838f83a50e' (see https://hub.docker.com/r/jupyter/pyspark-notebook/)
        command: start-notebook.sh --NotebookApp.password='sha1:22050c912871:90073c0c3a0cb0ed20cbeb8c70a46dd52ed39d4c'
        volumes:
            - ./jupyter-data:/home/jovyan/work
        ports: 
            - "8888:8888"
        networks:
            - energydata_nw
            
# simple visualization         
    visualizer:
        image: dockersamples/visualizer:stable
        ports:
          - "8099:8080"
        volumes:
          - "/var/run/docker.sock:/var/run/docker.sock"      
        networks:
            - energydata_nw            
networks:
    energydata_nw:
