{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.datastax.spark:spark-cassandra-connector_2.11:2.0.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"workshop-analytics\") \\\n",
    "    .config(\"spark.master\", \"spark://sparkmaster:7077\")\\\n",
    "    .config(\"spark.cassandra.connection.host\", \"node1\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ct = spark.read\\\n",
    ".format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"generation\", keyspace=\"energydata\")\\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*Scan org.apache.spark.sql.cassandra.CassandraSourceRelation@10b23498 [region#0,type#1,ts#2,value#3] ReadSchema: struct<region:string,type:string,ts:timestamp,value:double>\n"
     ]
    }
   ],
   "source": [
    "ct.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctpd = ct.filter(\"ts < cast('2012-01-11' as timestamp)\")\n",
    "#ctpd.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouped Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "ct_agg = ct \\\n",
    "    .withColumn('year', year(ct.ts)) \\\n",
    "    .withColumn('month', month(ct.ts)) \\\n",
    "    .filter(\"type == 'solar' AND region == 'DE'\") \\\n",
    "    .groupBy('type', 'region', 'year') \\\n",
    "    .agg( \\\n",
    "        mean(\"value\").alias(\"mean_generation\"),\n",
    "        max(\"value\").alias(\"max_generation\"),\n",
    "        sum(\"value\").alias(\"sum_generation\")\n",
    "        ) \\\n",
    "    .sort(desc('sum_generation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+------------------+--------------+--------------+\n",
      "| type|region|year|   mean_generation|max_generation|sum_generation|\n",
      "+-----+------+----+------------------+--------------+--------------+\n",
      "|solar|    DE|2015|3984.8301369863016|       25928.0|  1.39628448E8|\n",
      "|solar|    DE|2016| 3935.198906979392|       26252.0|  1.38251408E8|\n",
      "|solar|    DE|2014| 3738.812263284747|       24244.0|  1.30305085E8|\n",
      "|solar|    DE|2013|3389.9191370035483|       23998.0|  1.18470894E8|\n",
      "|solar|    DE|2012|3174.7929758652094|       22402.0|  1.11549526E8|\n",
      "|solar|    DE|2011|               0.0|           0.0|           0.0|\n",
      "+-----+------+----+------------------+--------------+--------------+\n",
      "\n",
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 4.57 s\n"
     ]
    }
   ],
   "source": [
    "#ct_agg.explain()\n",
    "%time ct_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ct_station = spark.read\\\n",
    ".format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"weather_station\", keyspace=\"energydata\")\\\n",
    ".load()\n",
    "\n",
    "ct_sensor = spark.read\\\n",
    ".format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"weather_sensor\", keyspace=\"energydata\")\\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_subset = ct_station\\\n",
    ".filter(\"lat < 50 and lon > 10\") \n",
    "\n",
    "sensor_subset = ct_sensor.filter(\"sensor=='h2'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2248704"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_subset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_subset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining with the Datasets API is limited, joins are not pushed down\n",
    "\n",
    "You would need to go with the RDD API (Scala only) using rdd.joinWithCassandraTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 4 ms, total: 16 ms\n",
      "Wall time: 44.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "351360"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "%time station_subset.join(sensor_subset, station_subset.id == sensor_subset.id).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
